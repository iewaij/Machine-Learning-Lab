{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relational Data and Visualization [30pts]\n",
    "In this problem, you will be analyzing the Twitter data we extracted using [this](https://dev.twitter.com/overview/api) api. The data consists of Twitter users (with unique handles) and their attributes (e.g., number of followers), some recent tweets posted by them with attributes (e.g., time stamp, number of retweets), and the follow relationship between the users. These are available in the three CSV files provided to you:\n",
    "- users.csv - users, user attributes\n",
    "- edges.csv - follow edges (directed, an edge from A to B means A follows B or B is a friend of A)\n",
    "- tweets.csv - tweets posted by the users along with its attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Relational Data [5pts + 6pts + 6pts]\n",
    "This question will guide you through loading Twitter data into an in-memory SQLite database and running some basic queries on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Task A: Load Twitter data into SQLite database [5pts]\n",
    "Your first task is to use the csv and sqlite3 python packages to load the three csv files we give you as relations (or tables) into an SQLite in-memory database.\n",
    "\n",
    "Loading the data from csv file into the database involves the following steps:\n",
    "1. Identify the schema of the table (for this problem, you will only need TEXT and INTEGER attribute types)\n",
    "2. Create a table with the identified schema\n",
    "3. Load the contents of csv in memory\n",
    "4. Insert every row of csv file as a record in the table\n",
    "\n",
    "You can refer to [sqlite3 documentation](https://docs.python.org/2/library/sqlite3.html) and the class lecture for steps 2 and 4. For step 3, refer to the [csv documentation](https://docs.python.org/2/library/csv.html). Be sure to name your tables `users`, `edges`, and `tweets`. \n",
    "\n",
    "Make sure to commit (the equivalent of Ctrl+S for databases) any changes you make to the database. [This](https://www.techopedia.com/definition/16/commit) page should give you an idea about why commit is essential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_twitter_data_sqlite3(conn, users_filepath, edges_filepath, tweets_filepath) :\n",
    "    \"\"\" Load twitter data in the three files as tables into an in-memory SQLite database\n",
    "    Input:\n",
    "        conn (sqlite3.Connection) : Connection object corresponding to the database; used to perform SQL commands.\n",
    "        users_filepath (str) : absolute/relative path to users.csv file\n",
    "        edges_filepath (str) : absolute/relative path to edges.csv file\n",
    "        tweets_filepath (str) : absolute/relative path to tweets.csv file\n",
    "    Output:\n",
    "        None\n",
    "    \"\"\"    \n",
    "    # identify schema\n",
    "    def identify_type(data):\n",
    "        first_line = data[1]\n",
    "        for e in first_line:\n",
    "            if re.search(r\"\\D\", e):\n",
    "                yield \"TEXT\"\n",
    "            else:\n",
    "                yield \"INTEGER\"\n",
    "\n",
    "    def identify_schema(data):\n",
    "        data_heading = data[0]\n",
    "        data_type = identify_type(data)\n",
    "        schema = \"\"\n",
    "        for h in data[0]:\n",
    "            schema += \" \".join((h, next(data_type) + \", \"))\n",
    "#             if h == \"screen_name\":\n",
    "#                 schema += \" \".join((h, next(data_type), \"PRIMARY KEY, \"))\n",
    "#             else:\n",
    "#                 schema += \" \".join((h, next(data_type) + \", \"))\n",
    "        return schema[:-2]\n",
    "    \n",
    "    # read csv into memory\n",
    "    def read_csv(filepath):\n",
    "        with open(filepath, 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            data = []\n",
    "            for row in reader:\n",
    "                data.append(row)\n",
    "        return data\n",
    "\n",
    "    users_reader = read_csv(users_filepath)\n",
    "    edges_reader = read_csv(edges_filepath)\n",
    "    tweets_reader = read_csv(tweets_filepath)\n",
    "    \n",
    "    # Create cursor\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # create sqlite table\n",
    "    def create_db(data, db_name):\n",
    "        db_schema = identify_schema(data)\n",
    "        # crete table can not use parameter substitution, use string method instead.\n",
    "        # Better do string check to avoid database injection\n",
    "        # see this answer here https://stackoverflow.com/questions/3247183/variable-table-name-in-sqlite\n",
    "        create_db_command = \"CREATE TABLE {} ({});\".format(db_name, db_schema)\n",
    "        cursor.execute(create_db_command)\n",
    "    \n",
    "    create_db(users_reader, \"users\")\n",
    "    create_db(edges_reader, \"edges\")\n",
    "    create_db(tweets_reader, \"tweets\")\n",
    "    \n",
    "    #Insert value\n",
    "    def insert_db(data, db_name):\n",
    "        value_len = len(data[0])\n",
    "        for row in data[1:]:\n",
    "            try:\n",
    "                value_command = tuple(row)\n",
    "                question_marks = \",\".join(\"?\" * value_len)\n",
    "                insert_command = \"\"\"INSERT INTO {} VALUES({});\"\"\".format(db_name, question_marks)\n",
    "                cursor.execute(insert_command, value_command)\n",
    "            except:\n",
    "                print(db_name)\n",
    "                print(row)\n",
    "                print(value_command)\n",
    "                print(insert_command)\n",
    "                raise\n",
    "    \n",
    "    insert_db(users_reader, \"users\")\n",
    "    insert_db(edges_reader, \"edges\")\n",
    "    insert_db(tweets_reader, \"tweets\")\n",
    "    \n",
    "    #commit\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your function will be called as in the cell below. The cell also contains some test code to display all tables in the database. You may want to write you own tests for the individual tables to verify that the data has been loaded properly. (e.g., number of tuples in each table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('users',)\n",
      "('edges',)\n",
      "('tweets',)\n",
      "('Donald J. Trump', 'realDonaldTrump', 'New York, NY', 'Wed Mar 18 13:46:38 +0000 2009', 42, 11397769, 33136, 38)\n",
      "('realDonaldTrump', 'Trump')\n",
      "('realDonaldTrump', 'Fri Sep 09 02:00:32 +0000 2016', 2859, 7030, 'Final poll results from NBC on last nights Commander-in-Chief Forum. Thank you! #ImWithYou #MAGA https://t.co/C5ipaxUN7B')\n"
     ]
    }
   ],
   "source": [
    "# AUTOLAB_IGNORE_START\n",
    "# connect to an in memory database\n",
    "conn = sqlite3.connect(\":memory:\")\n",
    "conn.text_factory = str\n",
    "# call to your function\n",
    "load_twitter_data_sqlite3(conn, 'users.csv', 'edges.csv', 'tweets.csv')\n",
    "# make sure to change the path to csv files appropriately\n",
    "cursor = conn.cursor()\n",
    "# prints all tables in the database\n",
    "for row in cursor.execute(\"SELECT name FROM sqlite_master WHERE type = 'table';\"):\n",
    "    print (row)\n",
    "# prints first rows of all tables in the database\n",
    "for row in cursor.execute(\"SELECT * FROM users LIMIT 1;\"):\n",
    "    print (row)\n",
    "for row in cursor.execute(\"SELECT * FROM edges LIMIT 1;\"):\n",
    "    print (row)\n",
    "for row in cursor.execute(\"SELECT * FROM tweets LIMIT 1;\"):\n",
    "    print (row)\n",
    "# AUTOLAB_IGNORE_STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Task B: Trending tweets in a topic [6pts]\n",
    "Twitter is regarded as an invaluable source of valuable information. Hence, one of the favorite tasks of data miners is the analyse the trending tweets in a given topic.\n",
    "\n",
    "This task requires you to retrieve the top N most trending tweets (in descending order of trending_score) about a given topic (which is a list of keywords). The following information may be useful:\n",
    "\n",
    "- A tweet is said to be about a given topic if it contains any of the given topical phrases/keywords.\n",
    "- We will use the following simple trending_score: retweet_count + favorite_count. Tweets with higher trending_score must be ranked before the ones with lower trending_score.\n",
    "- Your result must contain unique tweets. If a tweet text occurs multiple times, display it only once with its highest trending_score.\n",
    "- Break ties by sorting the tweets in alphabetical order.\n",
    "\n",
    "The output schema should be as follows:\n",
    "\n",
    "|tweet (TEXT)| trending_score (INTEGER) |\n",
    "| :--- |:--- |\n",
    "| | |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trending_tweets(cursor, topical_phrases=['Hillary', 'Clinton'], N=5):\n",
    "    \"\"\" Retrieves the top N trending tweets containing one or more of the given topical phrases.\n",
    "    Input:\n",
    "        cursor (sqlite3.Cursor): Cursor object to query the database.\n",
    "        topical_phrases (list of strings): A list of keywords identifying a topic.\n",
    "        N: Number of trending tweets to retrieve\n",
    "    Output:\n",
    "        results (sqlite3.Cursor): Cursor object which can be used to iterate over the retrieved records/tuples.\n",
    "    \"\"\"\n",
    "    # selct tweets from topical_phrases\n",
    "    like_query = \" OR \".join(\"'%#\" + topic + \"%'\" for topic in topical_phrases)\n",
    "    limit_query = N\n",
    "    query = \"\"\"\n",
    "            SELECT DISTINCT text, retweet_count + favorite_count AS trending_score \n",
    "            FROM tweets WHERE text LIKE {} \n",
    "            ORDER BY trending_score, text \n",
    "            LIMIT {};\n",
    "            \"\"\".format(like_query, N)\n",
    "    try:\n",
    "        results = cursor.execute(query)\n",
    "    except:\n",
    "        print(query)\n",
    "        raise\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default inputs to the function will retrieve 5 trending tweets about topic Hillary Clinton. You can view the output of your query using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Coming to a city near you! #VoteTrump2016 #MAGA  https://t.co/tyuCCz1fBX', 4)\n",
      "(\"RT @LGlick1: Let's let the people decide! @realDonaldTrump #VoteTrump #MAGA  https://t.co/ePfDb2Jd7Q\", 4)\n",
      "(\"It's all about listening to the people! @DanScavino @LynnePatton #VoteTrump #MAGA  https://t.co/Hs55YVJmiP\", 10)\n",
      "('You think? #MAGA #VoteTrump #NeverHillary https://t.co/FCe1dbno8y', 10)\n",
      "('@AdrienneM5 thank you, very nice. This is my 532 straight day on the job. Together we can truly #MAGA. We will finish the job.', 11)\n"
     ]
    }
   ],
   "source": [
    "# AUTOLAB_IGNORE_START\n",
    "results = trending_tweets(conn.cursor(), topical_phrases=['MAGA', 'Trump'], N=5)\n",
    "for row in results:\n",
    "    print(row)\n",
    "# AUTOLAB_IGNORE_STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Task C: Tweet recommendation [6pts]\n",
    "How does Twitter go about populating the feed for a user? While Twitter may use a comple models to do this, in this task, we will use a Simple Tweet Recommender (STR), which recommends a user's tweets to all users who follow him/her (without checking for possible duplicates; i.e., STR may recommend the same tweet twice if two of a user's friends have posted it).\n",
    "\n",
    "In this task, you will write a query to determine the number of tweets recommended to each user. Use only the snapshot of edges and tweets we have provided to you to do the recommendation. Report the results on the users present in the users table. (Hint: The number of records in your output should match that in the \"users\" table.) The order of results does not matter.\n",
    "\n",
    "The output schema should be:\n",
    "\n",
    "|screen_name (TEXT)| num_tweets (INTEGER) |\n",
    "| :--- |:--- |\n",
    "| | | |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AC360', 60)\n",
      "('AnnCLauer', 799)\n",
      "('AnnCoulter', 20)\n",
      "('AntonioBrown84', 40)\n",
      "('BleacherReport', 20)\n",
      "('BrendanAMurphy', 197)\n",
      "('CKGolferChic', 140)\n",
      "('CLewandowski_', 419)\n",
      "('CNNPolitics', 80)\n",
      "('CRTurnberry', 40)\n",
      "('CallawayGolf', 40)\n",
      "('Cmiddaughgolf', 40)\n",
      "('D29Gillian', 140)\n",
      "('DanScavino', 220)\n",
      "('DiamondandSilk', 240)\n",
      "('DonaldJTrumpJr', 120)\n"
     ]
    }
   ],
   "source": [
    "def num_tweets_in_feed(cursor):\n",
    "    \"\"\" Retrieves the number of tweets STR recommends to each Twitter user.\n",
    "    Input:\n",
    "        cursor (sqlite3.Cursor): Cursor object to query the database.\n",
    "    Output:\n",
    "        results (sqlite3.Cursor): Cursor object which can be used to iterate over the retrieved records/tuples.\n",
    "    \"\"\"\n",
    "    # detect friends -> freineds' tweets -> count\n",
    "    \n",
    "    query = \"\"\"\n",
    "            SELECT edges.screen_name, COUNT(tweets.text)\n",
    "            FROM edges\n",
    "            LEFT JOIN tweets ON edges.friend = tweets.screen_name\n",
    "            GROUP BY edges.screen_name;\n",
    "            \"\"\"\n",
    "    return cursor.execute(query)\n",
    "\n",
    "# AUTOLAB_IGNORE_START\n",
    "results = num_tweets_in_feed(conn.cursor())\n",
    "i = 0\n",
    "for row in results:\n",
    "    if row[1] > 0:\n",
    "        print (row)\n",
    "    if i>20:\n",
    "        break\n",
    "    i += 1\n",
    "# AUTOLAB_IGNORE_STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Visualization [2pts + 7pts + 4pts]\n",
    "In this question, you will load all data into pandas dataframes and analyse (and visualize!) some interesting trends using [matplotlib](http://matplotlib.org) python package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Task A: Load Twitter data using pandas [2pts]\n",
    "Fill in the following method stub and return the data frames for users, edges and tweets.\n",
    "\n",
    "Pandas will treat missing values as NaNs by default. However, for this assignment, you should treat missing values (i.e., empty strings in the csv files) as empty strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_twitter_data_pandas(users_filepath, edges_filepath, tweets_filepath):\n",
    "    \"\"\" Loads the Twitter data from the csv files into Pandas dataframes\n",
    "    Input:\n",
    "        users_filepath (str) : absolute/relative path to users.csv file\n",
    "        edges_filepath (str) : absolute/relative path to edges.csv file\n",
    "        tweets_filepath (str) : absolute/relative path to tweets.csv file\n",
    "    Output:\n",
    "        (pd.DataFrame, pd.DataFrame, pd.DataFrame) : A tuple of three dataframes, the first one for users,\n",
    "                                                    the second for edges and the third for tweets.\n",
    "    \"\"\"\n",
    "    users_df = pd.read_csv(users_filepath, na_values=\"\")\n",
    "    edges_df = pd.read_csv(edges_filepath, na_values=\"\")\n",
    "    tweets_df = pd.read_csv(tweets_filepath, na_values=\"\")\n",
    "    return (users_df, edges_df, tweets_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can test your function using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37890.12467444399"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AUTOLAB_IGNORE_START\n",
    "(users_df, edges_df, tweets_df) = load_twitter_data_pandas('users.csv', 'edges.csv', 'tweets.csv')\n",
    "# make sure to change the path to csv files appropriately\n",
    "# users_df.head()\n",
    "# edges_df.head()\n",
    "# tweets_df.head()\n",
    "friends_count = users_df.loc[:, \"friends_count\"]\n",
    "friends_count.std()\n",
    "# AUTOLAB_IGNORE_STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Task B: Correlation [4pts + 3pts]\n",
    "Statisticians and data analysts usually like to study about correlation between different observed variables. This helps uncover interesting patterns in the data such as causal relationships (e.g., snow on the road leads to increase in number of accidents). Correlation studies are important for multiple reasons:\n",
    "- While [correlation does not imply causation](https://en.wikipedia.org/wiki/Correlation_does_not_imply_causation), a lack of correlation implies a lack of causation. This can be used to rule out many causal relationships.\n",
    "- Correlation helps with prediction. The more closely related two variables are, the easier it is to predict one from the other.\n",
    "\n",
    "In this task, we ask you to plot the friends_count (on y-axis) vs the followers_count (on x-axis) using the matplotlib package. [Here](http://matplotlib.org/examples/shapes_and_collections/scatter_demo.html) is an example to get started with scatter plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "plt.style.use('ggplot')\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 5.0) # you should adjust this to fit your screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_friends_vs_followers(users_df):\n",
    "    \"\"\" Plots the friends_count (on y-axis) against the followers_count (on x-axis).\n",
    "    Input:\n",
    "        users_df (pd.DataFrame) : Dataframe containing Twitter user attributes,\n",
    "                                    as returned by load_twitter_data_pandas()\n",
    "    Output:\n",
    "        (matplotlib.collections.PathCollection) : The object returned by the scatter plot function\n",
    "    \"\"\"\n",
    "    friends_count = users_df.loc[:, \"friends_count\"]\n",
    "    followers_count = users_df.loc[:, \"followers_count\"]\n",
    "    friends_vs_followers = plt.scatter(followers_count, friends_count, s=5)\n",
    "    plt.xlabel('Followers')\n",
    "    plt.ylabel('Friends')\n",
    "    return plt\n",
    "# AUTOLAB_IGNORE_START\n",
    "p = plot_friends_vs_followers(users_df)\n",
    "plt.show()\n",
    "# AUTOLAB_IGNORE_STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see a correlation between these two variables from your scatter plot? Let's measure this quantitatively using the [Pearson's correlation coefficient](https://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient). \n",
    "\n",
    "For a set of observations $(X,Y) = [(x_1,y_1), (x_2,y_2), ... , (x_n,y_n)]$, the Pearson's correlation coefficient is a measure of the linear dependence between two variables $X$ and $Y$, giving a value between +1 and −1 inclusive, where 1 is total positive correlation, 0 is no correlation, and −1 is total negative correlation.\n",
    "\n",
    "$r=r_{xy}={\\frac {n\\sum x_{i}y_{i}-\\sum x_{i}\\sum y_{i}}{{\\sqrt {n\\sum x_{i}^{2}-(\\sum x_{i})^{2}}}~{\\sqrt {n\\sum y_{i}^{2}-(\\sum y_{i})^{2}}}}}$\n",
    "\n",
    "Now, fill in the following function to compute the Pearson's correlation coefficient between friends_count and followers_count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09\n"
     ]
    }
   ],
   "source": [
    "def correlation_coefficient(users_df):\n",
    "    \"\"\" Plots the friends_count (on y-axis) against the followers_count (on x-axis).\n",
    "    Input:\n",
    "        users_df (pd.DataFrame) : Dataframe containing Twitter user attributes,\n",
    "                                    as returned by load_twitter_data_pandas()\n",
    "    Output:\n",
    "        (double) : correlation coefficient between friends_count and followers_count\n",
    "    \"\"\"\n",
    "    friends_count = users_df.loc[:, \"friends_count\"]\n",
    "    followers_count = users_df.loc[:, \"followers_count\"]\n",
    "    covarience = friends_count.cov(followers_count)\n",
    "    r = covarience / (friends_count.std() * followers_count.std())\n",
    "    return round(r, 2)\n",
    "\n",
    "# AUTOLAB_IGNORE_START\n",
    "print (correlation_coefficient(users_df))\n",
    "# AUTOLAB_IGNORE_STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Task C: Degree distribution [4pts]\n",
    "If you are not familiar with graph theory and/or graph mining, skip the first paragraph.\n",
    "\n",
    "As you're familiar with graphs, you might know that the degree of a node is the number of connections it has to other nodes. A common statistic to look out for in the case of real world graphs is the degree distribution. Literature says degrees of nodes in real world graphs follow a [power law distribution](https://en.wikipedia.org/wiki/Power_law). The implication is that a scatter plot of num_users versus k (as we will define below) yields an almost straight line. In this task, we shall verify whether the given crawl of Twitter network satisfies this property.\n",
    "\n",
    "Let us call the number of friends a Twitter user has as his/her degree. The degree distribution is a histogram of the number of friends. Your task is to visualize this histogram. Use the default number of bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4da2a4488f94d7d976fecedba5594f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([  2.,   6.,   2.,   5.,   4.,   4.,   3.,   1.,   4., 148.]),\n",
       " array([  2. ,  11.8,  21.6,  31.4,  41.2,  51. ,  60.8,  70.6,  80.4,\n",
       "         90.2, 100. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def degree_distribution(edges_df):\n",
    "    \"\"\" Plots the distribution of .\n",
    "    Input:\n",
    "        edges_df (pd.DataFrame) : Dataframe containing Twitter edges,\n",
    "                        as returned by load_twitter_data_pandas()\n",
    "    Output:\n",
    "        (array, array, list of Patch objects) : Tuple of the values of the histogram bins, \n",
    "                        the edges of the bins and the silent list of individual patches used to create the histogram.\n",
    "    \"\"\"\n",
    "    friends_count = edges_df.groupby(by=\"screen_name\").count()\n",
    "    fig, hist = plt.subplots()\n",
    "    hist.set_title('Friends count histogram')\n",
    "    return hist.hist(friends_count.values)\n",
    "\n",
    "# AUTOLAB_IGNORE_START\n",
    "degree_distribution(edges_df)\n",
    "# AUTOLAB_IGNORE_STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you notice any surprising/unexpected pattern? What can you say about the way in which the Twitter data was collected?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Most of users have 100 friends, which indicates that data is not collected randomly but collected specificly starting from popular users and have an upperbound 100.*"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
